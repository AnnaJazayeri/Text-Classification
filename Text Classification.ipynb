{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6deb1bf",
   "metadata": {},
   "source": [
    "## Anna Jazayeri 131661209\n",
    "### Workshop 5\n",
    "### Text Mining BDM 550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18a3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a27c58",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abafb890",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_unlabel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m nb_classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Predict labels for the unlabeled data\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m nb_classifier\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtfidf_unlabel\u001b[49m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Print the classification report\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, nb_classifier\u001b[38;5;241m.\u001b[39mpredict(X_test), target_names\u001b[38;5;241m=\u001b[39mcategories))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_unlabel' is not defined"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download and unzip the labeled and unlabeled datasets\n",
    "with zipfile.ZipFile('labeled_dataset.zip', 'r') as labeled_zip:\n",
    "    labeled_zip.extractall('labeled_dataset')\n",
    "\n",
    "with zipfile.ZipFile('unlabeled_dataset.zip', 'r') as unlabeled_zip:\n",
    "    unlabeled_zip.extractall('unlabeled_dataset')\n",
    "\n",
    "# Assigning the labeled and unlabeled datasets\n",
    "label = 'labeled_dataset'\n",
    "unlabel = 'unlabeled_dataset'\n",
    "\n",
    "# Function to extract labels and texts from a file\n",
    "def extract_labels_and_texts(file_path):\n",
    "    labels = []\n",
    "    texts = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Splitting each line into label and text\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) == 2:\n",
    "                label, text = parts\n",
    "                labels.append(label)\n",
    "                texts.append(text)\n",
    "    return labels, texts\n",
    "\n",
    "# Lists to store labels and texts\n",
    "all_labels = []\n",
    "all_texts = []\n",
    "\n",
    "# Loop through labeled files to extract labels and texts\n",
    "for file in os.listdir(label):\n",
    "    if os.path.isfile(os.path.join(label, file)):\n",
    "        labels, texts = extract_labels_and_texts(os.path.join(label, file))\n",
    "        all_labels.extend(labels)\n",
    "        all_texts.extend(texts)\n",
    "\n",
    "# Tokenizing and cleaning the labeled texts\n",
    "clean_label = [remove_stop_punc(text) for text in all_texts]\n",
    "\n",
    "# Vectorizing with TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_label = tfidf_vectorizer.fit_transform(clean_label)\n",
    "\n",
    "# Create a Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Split the labeled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_label, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the unlabeled data\n",
    "predicted_labels = nb_classifier.predict(tfidf_unlabel)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, nb_classifier.predict(X_test), target_names=categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7585dd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m                     labeled_data\u001b[38;5;241m.\u001b[39mappend(remove_stop_punc(sentence\u001b[38;5;241m.\u001b[39mstrip()))\n\u001b[0;32m     42\u001b[0m                     labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m---> 44\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabeled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Feature extraction using CountVectorizer\u001b[39;00m\n\u001b[0;32m     47\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2277\u001b[0m     )\n\u001b[0;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download and unzip the labeled and unlabeled datasets\n",
    "with zipfile.ZipFile('labeled_dataset.zip', 'r') as labeled_zip:\n",
    "    labeled_zip.extractall('labeled_dataset')\n",
    "\n",
    "with zipfile.ZipFile('unlabeled_dataset.zip', 'r') as unlabeled_zip:\n",
    "    unlabeled_zip.extractall('unlabeled_dataset')\n",
    "\n",
    "# Step 1: Load the labeled dataset\n",
    "labeled_dataset_path = 'labeled_dataset'\n",
    "unlabeled_dataset_path = 'unlabeled_dataset'\n",
    "\n",
    "def remove_stop_punc(txt):\n",
    "    # Tokenizing the text\n",
    "    tokens = nltk.word_tokenize(txt)\n",
    "    # removing the stopwords and punctuations\n",
    "    tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stopwords.words('english')]\n",
    "    # removing remaining punctuation using regex\n",
    "    tokens = [re.sub(r'[^\\w\\s]', '', word) for word in tokens]\n",
    "    # now the cleaned tokens must be join together as a string\n",
    "    clean_txt = ' '.join(tokens)\n",
    "    return clean_txt\n",
    "\n",
    "labeled_data = []\n",
    "labels = []\n",
    "\n",
    "for file in os.listdir(labeled_dataset_path):\n",
    "    if os.path.isfile(os.path.join(labeled_dataset_path, file)):\n",
    "        with open(os.path.join(labeled_dataset_path, file), 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split(' ', 1)\n",
    "                if len(parts) == 2:\n",
    "                    label, sentence = parts\n",
    "                    labeled_data.append(remove_stop_punc(sentence.strip()))\n",
    "                    labels.append(label)\n",
    "                    \n",
    "X_train, X_test, y_train, y_test = train_test_split(labeled_data, labels, test_size=0.2, random_state=42)   \n",
    "                    \n",
    "# Feature extraction using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24580539",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue;\">Task 1: Preprocess the text to remove any stop words or punctuations.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da51387d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Download and unzip the labeled and unlabeled datasets\n",
    "with zipfile.ZipFile('labeled_dataset.zip', 'r') as labeled_zip:\n",
    "    labeled_zip.extractall('labeled_dataset')\n",
    "\n",
    "with zipfile.ZipFile('unlabeled_dataset.zip', 'r') as unlabeled_zip:\n",
    "    unlabeled_zip.extractall('unlabeled_dataset')\n",
    "\n",
    "# Step 1: Load the labeled dataset\n",
    "labeled_dataset_path = 'labeled_dataset'\n",
    "unlabeled_dataset_path = 'unlabeled_dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea17600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labeled_data = []\n",
    "labels = []\n",
    "\n",
    "for file in os.listdir(labeled_dataset_path):\n",
    "    if os.path.isfile(os.path.join(labeled_dataset_path, file)):\n",
    "        with open(os.path.join(labeled_dataset_path, file), 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split(' ', 1)\n",
    "                if len(parts) == 2:\n",
    "                    label, sentence = parts\n",
    "                    labeled_data.append(sentence)\n",
    "                    labels.append(label)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2227a862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract ###',\n",
       " 'the internet as level topology has been extensively studied over the past few years  little is known about the details of the as taxonomy',\n",
       " 'as  node  can represent a wide variety of organizations  e g   large isp  or small private business  university  with vastly different network characteristics  external connectivity patterns  network growth tendencies  and other properties that we can hardly neglect while working on veracious internet representations in simulation environments',\n",
       " 'this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet into a natural as taxonomy',\n",
       " 'successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   NUMBER  percent',\n",
       " 'release to the community the as level topology dataset augmented with   NUMBER   the as taxonomy information and  NUMBER   the set of as attributes we used to classify ases',\n",
       " 'believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the internet',\n",
       " 'introduction ###',\n",
       " 'rapid expansion of the internet in the last two decades has produced a large scale system of thousands of diverse  independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments',\n",
       " ' NUMBER  to  NUMBER  the number of globally routable as identifiers has increased from less than  NUMBER   NUMBER  to more than  NUMBER   NUMBER   exerting significant pressure on interdomain routing as well as other functional and structural parts of the internet',\n",
       " 'impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the internet infrastructure',\n",
       " 'particular  the as level topology is an intermix of networks owned and operated by many different organizations  e g   backbone providers  regional providers  access providers  universities and private companies',\n",
       " 'information that faithfully characterizes different as types is on the critical path toward understanding the structure of the internet  as well as for modeling its topology and growth',\n",
       " 'topology modeling  knowledge of as types is mandatory for augmenting synthetically constructed or measured as topologies with realistic intra as and inter as router level topologies',\n",
       " 'example  we expect the network of a dual homed university to be drastically different from that of a dual homed small company',\n",
       " 'university will likely contain dozens of internal routers  thousands of hosts  and many other network elements  switches  servers  firewalls',\n",
       " 'the other hand  the small company will most probably have a single router and a simple network topology',\n",
       " 'there is such a diversity among different network types  we cannot accurately augment the as level topology with appropriate router level topologies if we cannot MISC\\tcharacterize the composing ases',\n",
       " ' annotating the ases in the as topology with their types is a prerequisite for modeling the evolution of the internet  since different types of ases exhibit different growth patterns',\n",
       " 'example  internet service providers  isp  grow by attracting new customers and by engaging in business agreements with other isps',\n",
       " 'the other hand  small companies that connect to the internet through one or few isps do not grow significantly over time',\n",
       " ' categorizing different types of ases in the internet is necessary to identify network evolution patterns and develop accurate evolution models',\n",
       " 'as taxonomy is also necessary for mapping ip addresses to different types of users',\n",
       " 'example  in traffic analysis studies its often required to distinguish between packets that come from home and business users',\n",
       " 'an as taxonomy  its possible to realize this goal by checking the type of as that originates the prefix in which an ip address lies',\n",
       " 'this work  we introduce a radically new approach based on machine learning to construct a representative as taxonomy',\n",
       " 'develop an algorithm to classify ases based on empirically observed differences between as characteristics',\n",
       " 'use a large set of data from the internet routing registries  irr   CITATION  and from routeviews  CITATION  to identify intrinsic differences between ases of different types',\n",
       " ' we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ases into six representative classes that reflect ases with different network properties and infrastructures',\n",
       " 'derive macroscopic statistics on the different types of ases in the internet and validate our results using a sample of  NUMBER  manually identified as types',\n",
       " 'validation demonstrates that our classification algorithm achieves high accuracy   NUMBER   NUMBER  percent  of the examined classifications were correct',\n",
       " ' we make our results and our classifier publicly available to promote further research and understanding of the internet s structure and evolution',\n",
       " 'section  we start with a brief discussion of related work',\n",
       " ' describes the data we used  and in section  we specify the set of as classes we use in our experiments',\n",
       " ' introduces our classification approach and results',\n",
       " 'validate them in section  and conclude in section',\n",
       " 'abstract ###',\n",
       " 'the internet as level topology has been extensively studied over the past few years  little is known about the details of the as taxonomy',\n",
       " 'as  node  can represent a wide variety of organizations  e g   large isp  or small private business  university  with vastly different network characteristics  external connectivity patterns  network growth tendencies  and other properties that we can hardly neglect while working on veracious internet representations in simulation environments',\n",
       " 'this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet into a natural as taxonomy',\n",
       " 'successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   NUMBER  percent',\n",
       " 'release to the community the as level topology dataset augmented with   NUMBER   the as taxonomy information and  NUMBER   the set of as attributes we used to classify ases',\n",
       " 'believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the internet',\n",
       " 'introduction ###',\n",
       " 'rapid expansion of the internet in the last two decades has produced a large scale system of thousands of diverse  independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments',\n",
       " ' NUMBER  to  NUMBER  the number of globally routable as identifiers has increased from less than  NUMBER   NUMBER  to more than  NUMBER   NUMBER   exerting significant pressure on interdomain routing as well as other functional and structural parts of the internet',\n",
       " 'impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the internet infrastructure',\n",
       " 'particular  the as level topology is an intermix of networks owned and operated by many different organizations  e g   backbone providers  regional providers  access providers  universities and private companies',\n",
       " 'information that faithfully characterizes different as types is on the critical path toward understanding the structure of the internet  as well as for modeling its topology and growth',\n",
       " 'topology modeling  knowledge of as types is mandatory for augmenting synthetically constructed or measured as topologies with realistic intra as and inter as router level topologies',\n",
       " 'example  we expect the network of a dual homed university to be drastically different from that of a dual homed small company',\n",
       " 'university will likely contain dozens of internal routers  thousands of hosts  and many other network elements  switches  servers  firewalls',\n",
       " 'the other hand  the small company will most probably have a single router and a simple network topology',\n",
       " 'there is such a diversity among different network types  we cannot accurately augment the as level topology with appropriate router level topologies if we cannot characterize the composing ases',\n",
       " ' annotating the ases in the as topology with their types is a prerequisite for modeling the evolution of the internet  since different types of ases exhibit different growth patterns',\n",
       " 'example  internet service providers  isp  grow by attracting new customers and by engaging in business agreements with other isps',\n",
       " 'the other hand  small companies that connect to the internet through one or few isps do not grow significantly over time',\n",
       " ' categorizing different types of ases in the internet is necessary to identify network evolution patterns and develop accurate evolution models',\n",
       " 'as taxonomy is also necessary for mapping ip addresses to different types of users',\n",
       " 'example  in traffic analysis studies its often required to distinguish between packets that come from home and business users',\n",
       " 'an as taxonomy  its possible to realize this goal by checking the type of as that originates the prefix in which an ip address lies',\n",
       " 'this work  we introduce a radically new approach based on machine learning to construct a representative as taxonomy',\n",
       " 'develop an algorithm to classify ases based on empirically observed differences between as characteristics',\n",
       " 'use a large set of data from the internet routing registries  irr   CITATION  and from routeviews  CITATION  to identify intrinsic differences between ases of different types',\n",
       " ' we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ases into six representative classes that reflect ases with different network properties and infrastructures',\n",
       " 'derive macroscopic statistics on the different types of ases in the internet and validate our results using a sample of  NUMBER  manually identified as types',\n",
       " 'validation demonstrates that our classification algorithm achieves high accuracy   NUMBER   NUMBER  percent  of the examined classifications were correct',\n",
       " ' we make our results and our classifier publicly available to promote further research and understanding of the internet s structure and evolution',\n",
       " 'section  we start with a brief discussion of related work',\n",
       " ' describes the data we used  and in section  we specify the set of as classes we use in our experiments',\n",
       " ' introduces our classification approach and results',\n",
       " 'validate them in section  and conclude in section',\n",
       " 'abstract ###',\n",
       " 'Although the Internet AS-level topology has been extensively studied over the past few years, little is known about the details of the AS taxonomy',\n",
       " 'An AS \"node\" can represent a wide variety of organizations, e g , large ISP, or small private business, university, with vastly different network characteristics, external connectivity patterns, network growth tendencies, and other properties that we can hardly neglect while working on veracious Internet representations in simulation environments',\n",
       " 'In this paper, we introduce a radically new approach based on machine learning techniques to map all the ASes in the Internet into a natural AS taxonomy',\n",
       " 'We successfully classify ~95.3\\\\% of ASes with expected accuracy of ~78.1\\\\%',\n",
       " 'We release to the community the AS-level topology dataset augmented with: 1) the AS taxonomy information and 2) the set of AS attributes we used to classify ASes',\n",
       " 'We believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the Internet',\n",
       " 'introduction ###',\n",
       " 'The rapid expansion of the Internet in the last two decades has produced a large-scale system of thousands of diverse, independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments',\n",
       " 'From 1997 to 2005 the number of globally routable AS identifiers has increased from less than 2,000 to more than 20,000, exerting significant pressure on interdomain routing as well as other functional and structural parts of the Internet',\n",
       " 'This impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the Internet infrastructure',\n",
       " 'In particular, the AS-level topology is an intermix of networks owned and operated by many different organizations, e g , backbone providers, regional providers, access providers, universities and private companies',\n",
       " 'Statistical information that faithfully characterizes different AS types is on the critical path toward understanding the structure of the Internet, as well as for modeling its topology and growth',\n",
       " 'In topology modeling, knowledge of AS types is mandatory for augmenting synthetically constructed or measured AS topologies with realistic intra-AS and inter-AS router-level topologies',\n",
       " 'For example, we expect the network of a dual-homed university to be drastically different from that of a dual-homed small company',\n",
       " 'The university will likely contain dozens of internal routers, thousands of hosts, and many other network elements (switches, servers, firewalls)',\n",
       " 'On the other hand, the small company will most probably have a single router and a simple network topology',\n",
       " 'Since there is such a diversity among different network types, we cannot accurately augment the AS-level topology with appropriate router-level topologies if we cannot characterize the composing ASes',\n",
       " 'Moreover, annotating the ASes in the AS topology with their types is a prerequisite for modeling the evolution of the Internet, since different types of ASes exhibit different growth patterns',\n",
       " 'For example, Internet Service Providers (ISP) grow by attracting new customers and by engaging in business agreements with other ISPs',\n",
       " 'On the other hand, small companies that connect to the Internet through one or few ISPs do not grow significantly over time',\n",
       " 'Thus, categorizing different types of ASes in the Internet is necessary to identify network evolution patterns and develop accurate evolution models',\n",
       " 'An AS taxonomy is also necessary for mapping IP addresses to different types of users',\n",
       " 'For example, in traffic analysis studies its often required to distinguish between packets that come from home and business users',\n",
       " 'Given an AS taxonomy, its possible to realize this goal by checking the type of AS that originates the prefix in which an IP address lies',\n",
       " 'In this work, we introduce a radically new approach based on machine learning to construct a representative AS taxonomy',\n",
       " 'We develop an algorithm to classify ASes based on empirically observed differences between AS characteristics',\n",
       " 'We use a large set of data from the Internet Routing Registries~(IRR)~ CITATION  and from RouteViews~ CITATION  to identify intrinsic differences between ASes of different types',\n",
       " 'Then, we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ASes into six representative classes that reflect ASes with different network properties and infrastructures',\n",
       " 'We derive macroscopic statistics on the different types of ASes in the Internet and validate our results using a sample of~1200 manually identified AS types',\n",
       " 'Our validation demonstrates that our classification algorithm achieves high accuracy:~78 1\\\\% of the examined classifications were correct',\n",
       " \"Finally, we make our results and our classifier publicly available to promote further research and understanding of the Internet's structure and evolution\",\n",
       " 'In Section~ we start with a brief discussion of related work',\n",
       " 'Section~ describes the data we used, and in Section~ we specify the set of AS classes we use in our experiments',\n",
       " 'Section~ introduces our classification approach and results',\n",
       " 'We validate them in Section~ and conclude in Section~',\n",
       " 'abstract ###',\n",
       " 'this paper we derive the equations for loop corrected belief propagation on a continuous variable gaussian model',\n",
       " 'the exactness of the averages for belief propagation for gaussian models  a  different way of obtaining the covariances is found   based on belief propagation on cavity graphs',\n",
       " 'discuss the relation of this  loop correction algorithm to expectation propagation  algorithms for the case in which the model is no longer  gaussian  but slightly perturbed by nonlinear terms',\n",
       " 'introduction ###',\n",
       " 'passing techniques in graphical models allow for the computation of  approximate   marginal probabilities in a time interval scaling polynomially in the  model size',\n",
       " 'discovery has consequently revolutionized several  fields of applications in the past years  of which error correcting codes and vision are probably the most prominent examples',\n",
       " 'many cases  the corresponding graphs are loopy  implying either that the error resulting from the application of loopy belief propagation  bp  is negligible for the particular model  or it  can be tolerated for the particular purpose bp serves',\n",
       " 'other cases  more sophisticated refinements of bp are necessary  taking into account  part of  the loop errors',\n",
       " 'the optimal treatment of these   loop errors    motivates an active field of research  in which  different solutions applying to different model classes are developed',\n",
       " 'models involving many short loops   like on regular lattices  cvm type approaches work well  CITATION   or tree ep approaches  CITATION',\n",
       " 'latter may also be  applied to correct for an incidental large loop',\n",
       " 'frameworks like the region graphs of  CITATION   lead to general strategies for selecting the basic clusters underlying such approaches for general model classes',\n",
       " 'recent analysis has shown that the local update equations of bp may be interpreted as the zero order term of an expansion in   cavity connected correlations',\n",
       " 'quantities are parameterizations of the   cavity distributions     i e   the  distribution over neighbor variables of a central variable which has been removed from the graph',\n",
       " 'bethe approximation and bp are recovered when this  cavity distribution is assumed to factorize  whereas the first order correction to the local update equations is obtained when one takes into account the pair cumulants  CITATION',\n",
       " 'of these pair cumulants is possible with extra runs of bp  allowing for new polynomial time algorithms  reducing errors to order    when applying algorithms of which running time scales with an extra factor  of    CITATION',\n",
       " 'this scaling seems heavy  the large benefit of the approach is that it does not require selection of basic clusters or underlying  tree structures  since it takes into account the effect of all loops that contribute to nontrivial correlations in the cavity distribution at once',\n",
       " 'above   loop correction    strategy is applicable in the class of models where a perturbative expansion around the bethe approximation makes sense  i e   in models with large loops and relatively weak interactions',\n",
       " 'principal requirement  is that the magnitude of pair variable cumulants of cavity distributions is an order smaller than the  single variable cumulants  and third order cumulants are even smaller  etc',\n",
       " ' heuristics based on the strategy allow for other good algorithms  performing well outside these parameter regimes  CITATION',\n",
       " 'far the approach has been developed for discrete variable models on a more abstract  CITATION  versus practical level  CITATION',\n",
       " 'this paper we apply the idea to graphical models for continuous variables',\n",
       " 'derive the loop corrected belief propagation equations  for simple tractable gaussian models   yielding a message passing scheme that  besides the correct average marginals  also yields the correct variances',\n",
       " 'that we discuss some approaches potentially  applicable to cases in which extra function approximations are necessary   and the relation with expectation propagation',\n",
       " 'by product of our loop corrected belief propagation equations is an algorithm that calculates exact covariance matrices for gaussian models like the one discussed in  CITATION   but without explicitly using linear response',\n",
       " 'abstract ###',\n",
       " 'In this paper we derive the equations for Loop Corrected Belief Propagation on a continuous variable Gaussian model',\n",
       " 'Using the exactness of the averages for belief propagation for Gaussian models, a  different way of obtaining the covariances is found,  based on Belief Propagation on cavity graphs',\n",
       " 'We discuss the relation of this  loop correction algorithm to Expectation Propagation  algorithms for the case in which the model is no longer  Gaussian, but slightly perturbed by nonlinear terms',\n",
       " 'introduction ###',\n",
       " 'Message passing techniques in graphical models allow for the computation of (approximate)  marginal probabilities in a time interval scaling polynomially in the  model size',\n",
       " 'Their discovery has consequently revolutionized several  fields of applications in the past years, of which error correcting codes and vision are probably the most prominent examples',\n",
       " 'In many cases, the corresponding graphs are loopy, implying either that the error resulting from the application of loopy belief propagation (BP) is negligible for the particular model, or it  can be tolerated for the particular purpose BP serves',\n",
       " 'In other cases  more sophisticated refinements of BP are necessary, taking into account (part of) the loop errors',\n",
       " \"Finding the optimal treatment of these ``loop errors''  motivates an active field of research, in which  different solutions applying to different model classes are developed\",\n",
       " 'For models involving many short loops,  like on regular lattices, CVM type approaches work well  CITATION , or tree EP approaches  CITATION',\n",
       " 'The latter may also be  applied to correct for an incidental large loop',\n",
       " 'Unifying frameworks like the Region graphs of  CITATION   lead to general strategies for selecting the basic clusters underlying such approaches for general model classes',\n",
       " \"A recent analysis has shown that the local update equations of BP may be interpreted as the zero order term of an expansion in ``cavity connected correlations''\",\n",
       " \"These quantities are parameterizations of the ``cavity distributions'',  i e , the  distribution over neighbor variables of a central variable which has been removed from the graph\",\n",
       " 'The Bethe approximation and BP are recovered when this  cavity distribution is assumed to factorize, whereas the first order correction to the local update equations is obtained when one takes into account the pair cumulants  CITATION',\n",
       " 'Estimation of these pair cumulants is possible with extra runs of BP, allowing for new polynomial time algorithms, reducing errors to order  SYMBOL   when applying algorithms of which running time scales with an extra factor  of  SYMBOL   CITATION',\n",
       " 'Although this scaling seems heavy, the large benefit of the approach is that it does not require selection of basic clusters or underlying  tree-structures, since it takes into account the effect of all loops that contribute to nontrivial correlations in the cavity distribution at once',\n",
       " \"The above ``loop correction''  strategy is applicable in the class of models where a perturbative expansion around the Bethe approximation makes sense, i e , in models with large loops and relatively weak interactions\",\n",
       " 'The principal requirement  is that the magnitude of pair variable cumulants of cavity distributions is an order smaller than the  single variable cumulants, and third order cumulants are even smaller, etc',\n",
       " 'However, heuristics based on the strategy allow for other good algorithms  performing well outside these parameter regimes  CITATION',\n",
       " 'So far the approach has been developed for discrete variable models on a more abstract  CITATION  versus practical level  CITATION',\n",
       " 'In this paper we apply the idea to graphical models for continuous variables',\n",
       " 'We derive the loop corrected belief propagation equations  for simple tractable Gaussian models,  yielding a message passing scheme that, besides the correct average marginals, also yields the correct variances',\n",
       " 'Besides that we discuss some approaches potentially  applicable to cases in which extra function approximations are necessary,  and the relation with expectation propagation',\n",
       " 'A by-product of our loop corrected belief propagation equations is an algorithm that calculates exact covariance matrices for Gaussian models like the one discussed in  CITATION , but without explicitly using linear response',\n",
       " 'abstract ###',\n",
       " 'Defensive forecasting is a method of transforming laws of probability (stated in game-theoretic terms as strategies for Sceptic) into forecasting algorithms',\n",
       " \"There are two known varieties of defensive forecasting: ``continuous'', in which Sceptic's moves are assumed to depend on the forecasts in a (semi)continuous manner and which produces deterministic forecasts, and ``randomized'', in which the dependence of Sceptic's moves on the forecasts is arbitrary and Forecaster's moves are allowed to be randomized\",\n",
       " \"This note shows that the randomized variety can be obtained from the continuous variety by smearing Sceptic's moves to make them continuous\",\n",
       " 'New as compared to version 1 (17 August 2007) of this report: The assumption of version 1 that the outcome space  SYMBOL  is finite is relaxed, and now it is only assumed to be compact',\n",
       " 'In the case where  SYMBOL  is finite, it is shown that Forecaster can choose his randomized forecasts concentrated on a finite set of cardinality at most  SYMBOL',\n",
       " 'introduction ###',\n",
       " 'The continuous variety of defensive forecasting was essentially introduced by Levin  CITATION , but was later rediscovered by Kakade and Foster  CITATION  and Takemura  et al CITATION',\n",
       " \"The randomized variety was introduced (in the case of von Mises's version of the game-theoretic approach to probability) by Foster and Vohra  CITATION  and further developed by, among others, Sandroni  et al CITATION ; these papers, however, were only concerned with asymptotic calibration\",\n",
       " 'Non-asymptotic versions of the randomized variety were proposed by Sandroni  CITATION  (based on standard measure-theoretic probability) and Vovk and Shafer  CITATION  (based on game-theoretic probability)',\n",
       " 'Kakade and Foster  CITATION  noticed that some calibration results require very little randomization (this will be an important aspect of our Theorem )',\n",
       " 'This note states two simple results about defensive forecasting, Theorem  about the continuous variety and Theorem  about the randomized variety',\n",
       " \"The proof of Theorem  is obtained from the proof of Theorem  by blurring Sceptic's moves\",\n",
       " 'In our informal discussions we will be assuming that the set  SYMBOL  of all possible outcomes is finite, although we will try to make mathematical statements as general as possible',\n",
       " 'The reader who is only interested in the main ideas might choose to specialize Theorems  and  and their proofs to the case of finite  SYMBOL',\n",
       " 'abstract ###',\n",
       " 'generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used  independently of any algorithm',\n",
       " 'contrast  the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties',\n",
       " ' as in much of learning theory  existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed',\n",
       " 'many machine learning applications  however  this assumption does not hold',\n",
       " 'observations received by the learning algorithm often have some inherent temporal dependence',\n",
       " 'paper studies the scenario where the observations are drawn from a stationary   mixing or   mixing sequence  a widely adopted assumption in the study of non independent and identically distributed   processes that implies a dependence between observations weakening over time',\n",
       " 'prove novel and distinct stability based generalization bounds for stationary   mixing and   mixing sequences',\n",
       " 'bounds strictly generalize the bounds given in the independent and identically distributed   case and apply to all stable learning algorithms  thereby extending the use of stability bounds to non independent and identically distributed   scenarios',\n",
       " 'also illustrate the application of our   mixing generalization bounds to general classes of learning algorithms  including support vector regression  kernel ridge regression  and support vector machines  and many other kernel regularization based and relative entropy based regularization algorithms',\n",
       " 'novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non independent and identically distributed   scenarios',\n",
       " 'introduction ###',\n",
       " 'generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used  such as the vc dimension  covering numbers  or rademacher complexity',\n",
       " 'measures characterize a class of hypotheses  independently of any algorithm',\n",
       " 'contrast  the notion of algorithmic stability can be used to derive bounds that are tailored to specific learning algorithms and exploit their particular properties',\n",
       " 'learning algorithm is stable if the hypothesis it outputs varies in a limited way in response to small changes made to the training set',\n",
       " 'stability has been used effectively in the past to derive tight generalization bounds  CITATION',\n",
       " ' as in much of learning theory  existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed  independent and identically distributed',\n",
       " 'many machine learning applications  this assumption  however  does not hold  in fact  the independent and identically distributed   assumption is not tested or derived from any data analysis',\n",
       " 'observations received by the learning algorithm often have some inherent temporal dependence',\n",
       " 'is clear in system diagnosis or time series prediction problems',\n",
       " ' prices of different stocks on the same day  or of the same stock on different days  may be dependent',\n",
       " ' a less apparent time dependency may affect data sampled in many other tasks as well',\n",
       " 'paper studies the scenario where the observations are drawn from a stationary   mixing or   mixing sequence  a widely adopted assumption in the study of non independent and identically distributed   processes that implies a dependence between observations weakening over time  CITATION',\n",
       " 'prove novel and distinct stability based generalization bounds for stationary   mixing and   mixing sequences',\n",
       " 'bounds strictly generalize the bounds given in the independent and identically distributed   case and apply to all stable learning algorithms  thereby extending the usefulness of stability bounds to non independent and identically distributed   scenarios',\n",
       " 'proofs are based on the independent block technique described by  CITATION  and attributed to  CITATION   which is commonly used in such contexts',\n",
       " ' our analysis differs from previous uses of this technique in that the blocks of points considered are not of equal size',\n",
       " 'our analysis of stationary   mixing sequences  we make use of a generalized version of mcdiarmid s inequality  CITATION  that holds for   mixing sequences',\n",
       " 'leads to stability based generalization bounds with the standard exponential form',\n",
       " 'generalization bounds for stationary   mixing sequences cover a more general non independent and identically distributed   scenario and use the standard mcdiarmid s inequality  however  unlike the   mixing case  the   mixing bound presented here is not a purely exponential bound and contains an additive term depending on the mixing coefficient',\n",
       " 'also illustrate the application of our   mixing generalization bounds to general classes of learning algorithms  including support vector regression  svr   CITATION   kernel ridge regression  CITATION   and support vector machines  svms   CITATION',\n",
       " 'such as support vector regression  svr   CITATION  have been used in the context of time series prediction in which the independent and identically distributed   assumption does not hold  some with good experimental results  CITATION',\n",
       " 'our knowledge  the use of these algorithms in non independent and identically distributed   scenarios has not been previously supported by any theoretical analysis',\n",
       " 'stability bounds we give for svr  svms  and many other kernel regularization based and relative entropy based regularization algorithms can thus be viewed as the first theoretical basis for their use in such scenarios',\n",
       " 'following sections are organized as follows',\n",
       " 'section   we introduce the necessary definitions for the non independent and identically distributed   problems that we are considering and discuss the learning scenarios in that context',\n",
       " ' gives our main generalization bounds for stationary   mixing sequences based on stability  as well as the illustration of its applications to general kernel regularization based algorithms  including svr  krr  and svms  as well as to relative entropy based regularization algorithms',\n",
       " ' section  presents the first known stability bounds for the more general stationary   mixing scenario',\n",
       " 'abstract ###',\n",
       " 'Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, independently of any algorithm',\n",
       " 'In contrast, the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties',\n",
       " 'However, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed',\n",
       " 'In many machine learning applications, however, this assumption does not hold',\n",
       " 'The observations received by the learning algorithm often have some inherent temporal dependence',\n",
       " 'This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid  processes that implies a dependence between observations weakening over time',\n",
       " 'We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences',\n",
       " 'These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the use of stability-bounds to non-iid scenarios',\n",
       " 'We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression, Kernel Ridge Regression, and Support Vector Machines, and many other kernel regularization-based and relative entropy-based regularization algorithms',\n",
       " 'These novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non-iid scenarios',\n",
       " 'introduction ###',\n",
       " 'Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, such as the VC-dimension, covering numbers, or Rademacher complexity',\n",
       " 'These measures characterize a class of hypotheses, independently of any algorithm',\n",
       " 'In contrast, the notion of algorithmic stability can be used to derive bounds that are tailored to specific learning algorithms and exploit their particular properties',\n",
       " 'A learning algorithm is stable if the hypothesis it outputs varies in a limited way in response to small changes made to the training set',\n",
       " 'Algorithmic stability has been used effectively in the past to derive tight generalization bounds  CITATION',\n",
       " 'But, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed (iid)',\n",
       " 'In many machine learning applications, this assumption, however, does not hold; in fact, the iid assumption is not tested or derived from any data analysis',\n",
       " 'The observations received by the learning algorithm often have some inherent temporal dependence',\n",
       " 'This is clear in system diagnosis or time series prediction problems',\n",
       " 'Clearly, prices of different stocks on the same day, or of the same stock on different days, may be dependent',\n",
       " 'But, a less apparent time dependency may affect data sampled in many other tasks as well',\n",
       " 'This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid processes that implies a dependence between observations weakening over time  CITATION',\n",
       " 'We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences',\n",
       " 'These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the usefulness of stability-bounds to non-iid scenarios',\n",
       " 'Our proofs are based on the independent block technique described by  CITATION  and attributed to  CITATION , which is commonly used in such contexts',\n",
       " 'However, our analysis differs from previous uses of this technique in that the blocks of points considered are not of equal size',\n",
       " \"For our analysis of stationary  SYMBOL -mixing sequences, we make use of a generalized version of McDiarmid's inequality  CITATION  that holds for  SYMBOL -mixing sequences\",\n",
       " 'This leads to stability-based generalization bounds with the standard exponential form',\n",
       " \"Our generalization bounds for stationary  SYMBOL -mixing sequences cover a more general non-iid scenario and use the standard McDiarmid's inequality, however, unlike the  SYMBOL -mixing case, the  SYMBOL -mixing bound presented here is not a purely exponential bound and contains an additive term depending on the mixing coefficient\",\n",
       " 'We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression (SVR)  CITATION , Kernel Ridge Regression  CITATION , and Support Vector Machines (SVMs)  CITATION',\n",
       " 'Algorithms such as support vector regression (SVR)  CITATION  have been used in the context of time series prediction in which the iid assumption does not hold, some with good experimental results  CITATION',\n",
       " 'To our knowledge, the use of these algorithms in non-iid scenarios has not been previously supported by any theoretical analysis',\n",
       " 'The stability bounds we give for SVR, SVMs, and many other kernel regularization-based and relative entropy-based regularization algorithms can thus be viewed as the first theoretical basis for their use in such scenarios',\n",
       " 'The following sections are organized as follows',\n",
       " 'In Section~, we introduce the necessary definitions for the non-iid problems that we are considering and discuss the learning scenarios in that context',\n",
       " 'Section~ gives our main generalization bounds for stationary  SYMBOL -mixing sequences based on stability, as well as the illustration of its applications to general kernel regularization-based algorithms, including SVR, KRR, and SVMs, as well as to relative entropy-based regularization algorithms',\n",
       " 'Finally, Section~ presents the first known stability bounds for the more general stationary  SYMBOL -mixing scenario',\n",
       " 'abstract ###',\n",
       " 'Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, independently of any algorithm',\n",
       " 'In contrast, the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties',\n",
       " 'However, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed',\n",
       " 'In many machine learning applications, however, this assumption does not hold',\n",
       " 'The observations received by the learning algorithm often have some inherent temporal dependence',\n",
       " 'This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid  processes that implies a dependence between observations weakening over time',\n",
       " 'We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences',\n",
       " 'These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the use of stability-bounds to non-iid scenarios',\n",
       " 'We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression, Kernel Ridge Regression, and Support Vector Machines, and many other kernel regularization-based and relative entropy-based regularization algorithms',\n",
       " 'These novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non-iid scenarios',\n",
       " 'introduction ###',\n",
       " 'Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, such as the VC-dimension, covering numbers, or Rademacher complexity',\n",
       " 'These measures characterize a class of hypotheses, independently of any algorithm',\n",
       " 'In contrast, the notion of algorithmic stability can be used to derive bounds that are tailored to specific learning algorithms and exploit their particular properties',\n",
       " 'A learning algorithm is stable if the hypothesis it outputs varies in a limited way in response to small changes made to the training set',\n",
       " 'Algorithmic stability has been used effectively in the past to derive tight generalization bounds  CITATION',\n",
       " 'But, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed (iid)',\n",
       " 'In many machine learning applications, this assumption, however, does not hold; in fact, the iid assumption is not tested or derived from any data analysis',\n",
       " 'The observations received by the learning algorithm often have some inherent temporal dependence',\n",
       " 'This is clear in system diagnosis or time series prediction problems',\n",
       " 'Clearly, prices of different stocks on the same day, or of the same stock on different days, may be dependent',\n",
       " 'But, a less apparent time dependency may affect data sampled in many other tasks as well',\n",
       " 'This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid processes that implies a dependence between observations weakening over time  CITATION',\n",
       " 'We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences',\n",
       " 'These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the usefulness of stability-bounds to non-iid scenarios',\n",
       " 'Our proofs are based on the independent block technique described by  CITATION  and attributed to  CITATION , which is commonly used in such contextsMISC',\n",
       " 'However, our analysis differs from previous uses of this technique in that the blocks of points considered are not of equal size',\n",
       " \"For our analysis of stationary  SYMBOL -mixing sequences, we make use of a generalized version of McDiarmid's inequality  CITATION  that holds for  SYMBOL -mixing sequences\",\n",
       " 'This leads to stability-based generalization bounds with the standard exponential form',\n",
       " \"Our generalization bounds for stationary  SYMBOL -mixing sequences cover a more general non-iid scenario and use the standard McDiarmid's inequality, however, unlike the  SYMBOL -mixing case, the  SYMBOL -mixing bound presented here is not a purely exponential bound and contains an additive term depending on the mixing coefficient\",\n",
       " 'We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression (SVR)  CITATION , Kernel Ridge Regression  CITATION , and Support Vector Machines (SVMs)  CITATION',\n",
       " 'Algorithms such as support vector regression (SVR)  CITATION  have been used in the context of time series prediction in which the iid assumption does not hold, some with good experimental results  CITATION',\n",
       " 'To our knowledge, the use of these algorithms in non-iid scenarios has not been previously supported by any theoretical analysis',\n",
       " 'The stability bounds we give for SVR, SVMs, and many other kernel regularization-based and relative entropy-based regularization algorithms can thus be viewed as the first theoretical basis for their use in such scenarios',\n",
       " 'The following sections are organized as follows',\n",
       " 'In Section~, we introduce the necessary definitions for the non-iid problems that we are considering and discuss the learning scenarios in that context',\n",
       " 'Section~ gives our main generalization bounds for stationary  SYMBOL -mixing sequences based on stability, as well as the illustration of its applications to general kernel regularization-based algorithms, including SVR, KRR, and SVMs, as well as to relative entropy-based regularization algorithms',\n",
       " 'Finally, Section~ presents the first known stability bounds for the more general stationary  SYMBOL -mixing scenario',\n",
       " 'abstract ###',\n",
       " 'paper studies quantum annealing  qa  for clustering  which can be seen as an extension of simulated annealing  sa',\n",
       " 'derive a qa algorithm for clustering and propose an annealing schedule  which is crucial in practice',\n",
       " 'show the proposed qa algorithm finds better clustering assignments than sa',\n",
       " ' qa is as easy as sa to implement',\n",
       " 'introduction ###',\n",
       " 'is one of the most popular methods in data mining',\n",
       " ' clustering problems are formulated as optimization problems  which are solved by algorithms  for example the em algorithm or convex relaxation',\n",
       " ' clustering is typically np hard',\n",
       " 'simulated annealing  sa   CITATION  is a promising candidate',\n",
       " ' proved sa was able to find the global optimum with a slow cooling schedule of temperature',\n",
       " 'their schedule is in practice too slow for clustering of a large amount of data  it is well known that sa still finds a reasonably good solution even with a faster schedule than what  citeauthor geman NUMBER   proposed',\n",
       " 'statistical mechanics  quantum annealing  qa  has been proposed as a novel alternative to sa  CITATION',\n",
       " 'adds another dimension     to sa for annealing  see fig',\n",
       " ' it can be seen as an extension of sa',\n",
       " 'has succeeded in specific problems  e g the ising model in statistical mechanics  and it is still unclear that qa works better than sa in general',\n",
       " 'do not actually think qa intuitively helps clustering  but we apply qa to clustering just as procedure to derive an algorithm',\n",
       " 'derived qa algorithm depends on the definition of quantum effect',\n",
       " 'propose quantum effect    which leads to a search strategy fit to clustering',\n",
       " 'contribution is 1) to propose a qa based optimization algorithm for clustering in particular quantum effect for clustering and a good annealing schedule  which is crucial for applications 2) and to experimentally show the proposed algorithm optimizes clustering assignments better than sa',\n",
       " 'also show the proposed algorithm is as easy as sa to implement',\n",
       " '\\tthe algorithm we propose is a markov chain monte carlo  mcmc  sampler  which we call qa st sampler',\n",
       " 'we explain later  a naive qa sampler is intractable even with mcmc',\n",
       " ' we approximate qa by the suzuki trotter  st  expansion  CITATION  to derive a tractable sampler  which is the qa st sampler',\n",
       " 'st looks like parallel   sas with interaction    see fig',\n",
       " 'the beginning of the annealing process  qa st is almost the same as   sas',\n",
       " ' qa st finds    local  optima independently',\n",
       " 'the annealing process continues  interaction   in fig becomes stronger to move   states closer',\n",
       " 'st at the end picks up the state with the lowest energy in   states as the final solution',\n",
       " 'st with the proposed quantum effect   works well for clustering',\n",
       " 'is an example where data points are grouped into four clusters',\n",
       " 'and SYMBOL are locally optimal and   is globally optimal',\n",
       " 'SYMBOL is equal to two and SYMBOL and SYMBOL in fig correspond to SYMBOL and SYMBOL in fig',\n",
       " '  and   are local optima  the interaction   in fig allows   and   to search for a better clustering assignment between   and',\n",
       " 'effect   defines the distance metric of clustering assignments',\n",
       " 'this case  the proposed   locates   between   and',\n",
       " ' the interaction   gives good chance to go to   because   makes   and   closer  see fig',\n",
       " 'proposed algorithm actually finds   from   and',\n",
       " 'is just an example',\n",
       " ' a similar situation often occurs in clustering',\n",
       " 'algorithms in most cases give   almost   globally optimal solutions like   and    where the majority of data points are well clustered  but some of them are not',\n",
       " ' a better clustering assignment can be constructed by picking up well clustered data points from many sub optimal clustering assignments',\n",
       " 'an assignment constructed in such a way is located between the sub optimal ones by the proposed quantum effect   so that qa st can find a better assignment between sub optimal ones']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed7849e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###',\n",
       " 'MISC\\talthough',\n",
       " 'MISC\\tan',\n",
       " 'AIMX\\tin',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\twe',\n",
       " '###',\n",
       " 'MISC\\tthe',\n",
       " 'MISC\\tfrom',\n",
       " 'MISC\\tthis',\n",
       " 'MISC\\tin',\n",
       " 'MISC\\tstatistical',\n",
       " 'MISC\\tin',\n",
       " 'MISC\\tfor',\n",
       " 'MISC\\tthe',\n",
       " 'MISC\\ton',\n",
       " 'MISC\\tsince',\n",
       " 'MISC\\tmoreover',\n",
       " 'MISC\\tfor',\n",
       " 'MISC\\ton',\n",
       " 'MISC\\tthus',\n",
       " 'MISC\\tan',\n",
       " 'MISC\\tfor',\n",
       " 'MISC\\tgiven',\n",
       " 'AIMX\\tin',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\twe',\n",
       " 'AIMX\\tthen',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\tour',\n",
       " 'OWNX\\tfinally',\n",
       " 'OWNX\\tin',\n",
       " 'OWNX\\tsection',\n",
       " 'OWNX\\tsection',\n",
       " 'OWNX\\twe',\n",
       " '###',\n",
       " 'MISC\\talthough',\n",
       " 'MISC\\tan',\n",
       " 'AIMX\\tin',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\twe',\n",
       " '###',\n",
       " 'MISC\\tthe',\n",
       " 'MISC\\tfrom',\n",
       " 'MISC\\tthis',\n",
       " 'MISC\\tin',\n",
       " 'MISC\\tstatistical',\n",
       " 'MISC\\tin',\n",
       " 'MISC\\tfor',\n",
       " 'MISC\\tthe',\n",
       " 'MISC\\ton',\n",
       " 'MISC\\tsince',\n",
       " 'MISC\\tmoreover',\n",
       " 'MISC\\tfor',\n",
       " 'MISC\\ton',\n",
       " 'MISC\\tthus',\n",
       " 'MISC\\tan',\n",
       " 'MISC\\tfor',\n",
       " 'MISC\\tgiven',\n",
       " 'AIMX\\tin',\n",
       " 'AIMX\\twe',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\tthen',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\tour',\n",
       " 'OWNX\\tfinally',\n",
       " 'BASE\\tin',\n",
       " 'OWNX\\tsection',\n",
       " 'OWNX\\tsection',\n",
       " 'OWNX\\twe',\n",
       " '###',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " '###',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'BASE',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " '###',\n",
       " 'AIMX\\tin',\n",
       " 'OWNX\\tusing',\n",
       " 'OWNX\\twe',\n",
       " '###',\n",
       " 'MISC\\tmessage',\n",
       " 'MISC\\ttheir',\n",
       " 'MISC\\tin',\n",
       " 'MISC\\tin',\n",
       " 'MISC\\tfinding',\n",
       " 'MISC\\tfor',\n",
       " 'MISC\\tthe',\n",
       " 'MISC\\tunifying',\n",
       " 'MISC\\ta',\n",
       " 'MISC\\tthese',\n",
       " 'MISC\\tthe',\n",
       " 'MISC\\testimation',\n",
       " 'MISC\\talthough',\n",
       " 'MISC\\tthe',\n",
       " 'MISC\\tthe',\n",
       " 'MISC\\thowever',\n",
       " 'CONT\\tso',\n",
       " 'AIMX\\tin',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\tbesides',\n",
       " 'CONT\\ta',\n",
       " '###',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'AIMX',\n",
       " '###',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " '###',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " '###',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'BASE',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'MISC',\n",
       " '###',\n",
       " 'CONT\\tmost',\n",
       " 'CONT\\tin',\n",
       " 'CONT\\thowever',\n",
       " 'CONT\\tin',\n",
       " 'CONT\\tthe',\n",
       " 'AIMX\\tthis',\n",
       " 'OWNX\\twe',\n",
       " 'BASE\\tthese',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX\\tthese',\n",
       " '###',\n",
       " 'CONT\\tmost',\n",
       " 'CONT\\tthese',\n",
       " 'CONT\\tin',\n",
       " 'CONT\\ta',\n",
       " 'CONT\\talgorithmic',\n",
       " 'CONT\\tbut',\n",
       " 'CONT\\tin',\n",
       " 'CONT\\tthe',\n",
       " 'CONT\\tthis',\n",
       " 'CONT\\tclearly',\n",
       " 'CONT\\tbut',\n",
       " 'AIMX\\tthis',\n",
       " 'OWNX\\twe',\n",
       " 'BASE\\tthese',\n",
       " 'BASE\\tour',\n",
       " 'CONT\\thowever',\n",
       " 'BASE\\tfor',\n",
       " 'BASE\\tthis',\n",
       " 'OWNX\\tour',\n",
       " 'OWNX\\twe',\n",
       " 'CONT\\talgorithms',\n",
       " 'CONT\\tto',\n",
       " 'CONT\\tthe',\n",
       " 'OWNX\\tthe',\n",
       " 'OWNX\\tin',\n",
       " 'OWNX\\tsection',\n",
       " 'OWNX\\tfinally',\n",
       " '###',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'AIMX',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " '###',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'AIMX',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'BASE',\n",
       " 'CONT',\n",
       " 'BASE',\n",
       " 'BASE',\n",
       " 'CONT',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'CONT',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " '###',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " '###',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'AIMX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'BASE',\n",
       " 'CONT',\n",
       " 'BASE',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'MISC',\n",
       " 'MISC',\n",
       " 'OWNX',\n",
       " 'MISC',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " 'OWNX',\n",
       " '###',\n",
       " 'AIMX\\tthis',\n",
       " 'OWNX\\twe',\n",
       " 'CONT\\texperiments',\n",
       " 'CONT\\tfurthermore',\n",
       " '###',\n",
       " 'MISC\\tclustering',\n",
       " 'MISC\\ttypically',\n",
       " 'MISC\\thowever',\n",
       " 'MISC\\tthe',\n",
       " 'MISC\\tCITATION',\n",
       " 'CONT\\talthough',\n",
       " 'CONT\\tin',\n",
       " 'CONT\\tqa',\n",
       " 'BASE\\tthus',\n",
       " 'MISC\\tqa',\n",
       " 'OWNX\\twe',\n",
       " 'MISC\\ta',\n",
       " 'OWNX\\twe',\n",
       " 'AIMX\\tour',\n",
       " 'OWNX\\twe',\n",
       " 'OWNX',\n",
       " 'OWNX\\tas',\n",
       " 'OWNX\\tthus',\n",
       " 'OWNX\\tqa',\n",
       " 'OWNX\\tat',\n",
       " 'OWNX\\thence',\n",
       " 'OWNX\\tas',\n",
       " 'OWNX\\tqa',\n",
       " 'OWNX\\tqa',\n",
       " 'OWNX\\tfig',\n",
       " 'OWNX\\tSYMBOL',\n",
       " 'OWNX\\tsuppose',\n",
       " 'OWNX\\talthough',\n",
       " 'OWNX\\tquantum',\n",
       " 'OWNX\\tin',\n",
       " 'OWNX\\tthus',\n",
       " 'OWNX\\tthe',\n",
       " 'OWNX\\tfig',\n",
       " 'MISC\\thowever',\n",
       " 'MISC\\tclustering',\n",
       " 'MISC\\tthus',\n",
       " 'MISC\\tnote']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "700c89fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabeled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Feature extraction using TfidfVectorizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2277\u001b[0m     )\n\u001b[0;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(labeled_data, labels, test_size=0.2, random_state=42)   \n",
    "                    \n",
    "# Feature extraction using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division= np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2343d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc43af1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m labeled_data \u001b[38;5;241m=\u001b[39m [sentence \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m labeled_data \u001b[38;5;28;01mif\u001b[39;00m sentence\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, confusion_matrix(\u001b[43my_test\u001b[49m, y_pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "labeled_zip_path = 'labeled_dataset.zip'\n",
    "unlabeled_zip_path = 'unlabeled_dataset.zip'\n",
    "\n",
    "if not os.path.exists(labeled_zip_path) or not os.path.exists(unlabeled_zip_path):\n",
    "    print(\"Error: ZIP files not found.\")\n",
    "else:\n",
    "    with zipfile.ZipFile(labeled_zip_path, 'r') as labeled_zip:\n",
    "        labeled_zip.extractall('labeled_dataset')\n",
    "\n",
    "    with zipfile.ZipFile(unlabeled_zip_path, 'r') as unlabeled_zip:\n",
    "        unlabeled_zip.extractall('unlabeled_dataset')\n",
    "labeled_data = [sentence for sentence in labeled_data if sentence.strip()]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ba55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bb4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3b619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b99acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folder containing the .txt files\n",
    "folder_path = Path(\"C:\\\\Users\\\\annaj\\\\OneDrive\\\\Desktop\\\\Git Projects\\\\Text-Classification\\\\labeled_dataset\")\n",
    "\n",
    "# Get a list of all .txt files in the folder\n",
    "txt_files = folder_path.glob('*.txt')\n",
    "\n",
    "# Create a list to store the content of each file\n",
    "file_contents = []\n",
    "\n",
    "# Loop through each .txt file and append its content to the list\n",
    "for txt_file in txt_files:\n",
    "    with open(txt_file, 'r') as file:\n",
    "        content = file.read()\n",
    "        file_contents.append(content)\n",
    "\n",
    "# Concatenate the content using pandas\n",
    "concatenated_content = pd.concat([pd.Series(file_contents)], ignore_index=True)\n",
    "\n",
    "# Save the concatenated content to a new file\n",
    "output_file_path = \"C:\\\\Users\\\\annaj\\\\OneDrive\\\\Desktop\\\\Git Projects\\\\Text-Classification\\\\la.txt\"\n",
    "concatenated_content.to_csv(output_file_path, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f84c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33086eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9deac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c610a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55bdebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df70a34a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract',\n",
       " 'internet level topology extensively studied past years little known details taxonomy',\n",
       " 'node represent wide variety organizations e g large isp small private business university vastly different network characteristics external connectivity patterns network growth tendencies properties hardly neglect working veracious internet representations simulation environments',\n",
       " 'paper introduce radically new approach based machine learning techniques map ases internet natural taxonomy',\n",
       " 'successfully classify number number percent ases expected accuracy number number percent',\n",
       " 'release community level topology dataset augmented number taxonomy information number set attributes used classify ases',\n",
       " 'believe dataset serve invaluable addition understanding structure evolution internet',\n",
       " 'introduction',\n",
       " 'rapid expansion internet last two decades produced large scale system thousands diverse independently managed networks collectively provide global connectivity across wide spectrum geopolitical environments',\n",
       " 'number number number globally routable identifiers increased less number number number number exerting significant pressure interdomain routing well functional structural parts internet',\n",
       " 'impressive growth resulted heterogenous highly complex system challenges accurate realistic modeling internet infrastructure',\n",
       " 'particular level topology intermix networks owned operated many different organizations e g backbone providers regional providers access providers universities private companies',\n",
       " 'information faithfully characterizes different types critical path toward understanding structure internet well modeling topology growth',\n",
       " 'topology modeling knowledge types mandatory augmenting synthetically constructed measured topologies realistic intra inter router level topologies',\n",
       " 'example expect network dual homed university drastically different dual homed small company',\n",
       " 'university likely contain dozens internal routers thousands hosts many network elements switches servers firewalls',\n",
       " 'hand small company probably single router simple network topology',\n",
       " 'diversity among different network types accurately augment level topology appropriate router level topologies misc characterize composing ases',\n",
       " 'annotating ases topology types prerequisite modeling evolution internet since different types ases exhibit different growth patterns',\n",
       " 'example internet service providers isp grow attracting new customers engaging business agreements isps',\n",
       " 'hand small companies connect internet one isps grow significantly time',\n",
       " 'categorizing different types ases internet necessary identify network evolution patterns develop accurate evolution models',\n",
       " 'taxonomy also necessary mapping ip addresses different types users',\n",
       " 'example traffic analysis studies often required distinguish packets come home business users',\n",
       " 'taxonomy possible realize goal checking type originates prefix ip address lies',\n",
       " 'work introduce radically new approach based machine learning construct representative taxonomy',\n",
       " 'develop algorithm classify ases based empirically observed differences characteristics',\n",
       " 'use large set data internet routing registries irr citation routeviews citation identify intrinsic differences ases different types',\n",
       " 'employ novel machine learning technique build classification algorithm exploits differences classify ases six representative classes reflect ases different network properties infrastructures',\n",
       " 'derive macroscopic statistics different types ases internet validate results using sample number manually identified types',\n",
       " 'validation demonstrates classification algorithm achieves high accuracy number number percent examined classifications correct',\n",
       " 'make results classifier publicly available promote research understanding internet structure evolution',\n",
       " 'section start brief discussion related work',\n",
       " 'describes data used section specify set classes use experiments',\n",
       " 'introduces classification approach results',\n",
       " 'validate section conclude section',\n",
       " 'abstract',\n",
       " 'internet level topology extensively studied past years little known details taxonomy',\n",
       " 'node represent wide variety organizations e g large isp small private business university vastly different network characteristics external connectivity patterns network growth tendencies properties hardly neglect working veracious internet representations simulation environments',\n",
       " 'paper introduce radically new approach based machine learning techniques map ases internet natural taxonomy',\n",
       " 'successfully classify number number percent ases expected accuracy number number percent',\n",
       " 'release community level topology dataset augmented number taxonomy information number set attributes used classify ases',\n",
       " 'believe dataset serve invaluable addition understanding structure evolution internet',\n",
       " 'introduction',\n",
       " 'rapid expansion internet last two decades produced large scale system thousands diverse independently managed networks collectively provide global connectivity across wide spectrum geopolitical environments',\n",
       " 'number number number globally routable identifiers increased less number number number number exerting significant pressure interdomain routing well functional structural parts internet',\n",
       " 'impressive growth resulted heterogenous highly complex system challenges accurate realistic modeling internet infrastructure',\n",
       " 'particular level topology intermix networks owned operated many different organizations e g backbone providers regional providers access providers universities private companies',\n",
       " 'information faithfully characterizes different types critical path toward understanding structure internet well modeling topology growth',\n",
       " 'topology modeling knowledge types mandatory augmenting synthetically constructed measured topologies realistic intra inter router level topologies',\n",
       " 'example expect network dual homed university drastically different dual homed small company',\n",
       " 'university likely contain dozens internal routers thousands hosts many network elements switches servers firewalls',\n",
       " 'hand small company probably single router simple network topology',\n",
       " 'diversity among different network types accurately augment level topology appropriate router level topologies characterize composing ases',\n",
       " 'annotating ases topology types prerequisite modeling evolution internet since different types ases exhibit different growth patterns',\n",
       " 'example internet service providers isp grow attracting new customers engaging business agreements isps',\n",
       " 'hand small companies connect internet one isps grow significantly time',\n",
       " 'categorizing different types ases internet necessary identify network evolution patterns develop accurate evolution models',\n",
       " 'taxonomy also necessary mapping ip addresses different types users',\n",
       " 'example traffic analysis studies often required distinguish packets come home business users',\n",
       " 'taxonomy possible realize goal checking type originates prefix ip address lies',\n",
       " 'work introduce radically new approach based machine learning construct representative taxonomy',\n",
       " 'develop algorithm classify ases based empirically observed differences characteristics',\n",
       " 'use large set data internet routing registries irr citation routeviews citation identify intrinsic differences ases different types',\n",
       " 'employ novel machine learning technique build classification algorithm exploits differences classify ases six representative classes reflect ases different network properties infrastructures',\n",
       " 'derive macroscopic statistics different types ases internet validate results using sample number manually identified types',\n",
       " 'validation demonstrates classification algorithm achieves high accuracy number number percent examined classifications correct',\n",
       " 'make results classifier publicly available promote research understanding internet structure evolution',\n",
       " 'section start brief discussion related work',\n",
       " 'describes data used section specify set classes use experiments',\n",
       " 'introduces classification approach results',\n",
       " 'validate section conclude section',\n",
       " 'abstract',\n",
       " 'although internet topology extensively studied past years little known details taxonomy',\n",
       " 'node represent wide variety organizations e g large isp small private business university vastly different network characteristics external connectivity patterns network growth tendencies properties hardly neglect working veracious internet representations simulation environments',\n",
       " 'paper introduce radically new approach based machine learning techniques map ases internet natural taxonomy',\n",
       " 'successfully classify ases expected accuracy',\n",
       " 'release community topology dataset augmented 1 taxonomy information 2 set attributes used classify ases',\n",
       " 'believe dataset serve invaluable addition understanding structure evolution internet',\n",
       " 'introduction',\n",
       " 'rapid expansion internet last two decades produced system thousands diverse independently managed networks collectively provide global connectivity across wide spectrum geopolitical environments',\n",
       " '1997 2005 number globally routable identifiers increased less exerting significant pressure interdomain routing well functional structural parts internet',\n",
       " 'impressive growth resulted heterogenous highly complex system challenges accurate realistic modeling internet infrastructure',\n",
       " 'particular topology intermix networks owned operated many different organizations e g backbone providers regional providers access providers universities private companies',\n",
       " 'statistical information faithfully characterizes different types critical path toward understanding structure internet well modeling topology growth',\n",
       " 'topology modeling knowledge types mandatory augmenting synthetically constructed measured topologies realistic topologies',\n",
       " 'example expect network university drastically different small company',\n",
       " 'university likely contain dozens internal routers thousands hosts many network elements switches servers firewalls',\n",
       " 'hand small company probably single router simple network topology',\n",
       " 'since diversity among different network types accurately augment topology appropriate topologies characterize composing ases',\n",
       " 'moreover annotating ases topology types prerequisite modeling evolution internet since different types ases exhibit different growth patterns',\n",
       " 'example internet service providers isp grow attracting new customers engaging business agreements isps',\n",
       " 'hand small companies connect internet one isps grow significantly time',\n",
       " 'thus categorizing different types ases internet necessary identify network evolution patterns develop accurate evolution models',\n",
       " 'taxonomy also necessary mapping ip addresses different types users',\n",
       " 'example traffic analysis studies often required distinguish packets come home business users',\n",
       " 'given taxonomy possible realize goal checking type originates prefix ip address lies',\n",
       " 'work introduce radically new approach based machine learning construct representative taxonomy',\n",
       " 'develop algorithm classify ases based empirically observed differences characteristics',\n",
       " 'use large set data internet routing irr citation citation identify intrinsic differences ases different types',\n",
       " 'employ novel machine learning technique build classification algorithm exploits differences classify ases six representative classes reflect ases different network properties infrastructures',\n",
       " 'derive macroscopic statistics different types ases internet validate results using sample manually identified types',\n",
       " 'validation demonstrates classification algorithm achieves high accuracy examined classifications correct',\n",
       " 'finally make results classifier publicly available promote research understanding internet structure evolution',\n",
       " 'start brief discussion related work',\n",
       " 'describes data used specify set classes use experiments',\n",
       " 'introduces classification approach results',\n",
       " 'validate conclude',\n",
       " 'abstract',\n",
       " 'paper derive equations loop corrected belief propagation continuous variable gaussian model',\n",
       " 'exactness averages belief propagation gaussian models different way obtaining covariances found based belief propagation cavity graphs',\n",
       " 'discuss relation loop correction algorithm expectation propagation algorithms case model longer gaussian slightly perturbed nonlinear terms',\n",
       " 'introduction',\n",
       " 'passing techniques graphical models allow computation approximate marginal probabilities time interval scaling polynomially model size',\n",
       " 'discovery consequently revolutionized several fields applications past years error correcting codes vision probably prominent examples',\n",
       " 'many cases corresponding graphs loopy implying either error resulting application loopy belief propagation bp negligible particular model tolerated particular purpose bp serves',\n",
       " 'cases sophisticated refinements bp necessary taking account part loop errors',\n",
       " 'optimal treatment loop errors motivates active field research different solutions applying different model classes developed',\n",
       " 'models involving many short loops like regular lattices cvm type approaches work well citation tree ep approaches citation',\n",
       " 'latter may also applied correct incidental large loop',\n",
       " 'frameworks like region graphs citation lead general strategies selecting basic clusters underlying approaches general model classes',\n",
       " 'recent analysis shown local update equations bp may interpreted zero order term expansion cavity connected correlations',\n",
       " 'quantities parameterizations cavity distributions e distribution neighbor variables central variable removed graph',\n",
       " 'bethe approximation bp recovered cavity distribution assumed factorize whereas first order correction local update equations obtained one takes account pair cumulants citation',\n",
       " 'pair cumulants possible extra runs bp allowing new polynomial time algorithms reducing errors order applying algorithms running time scales extra factor citation',\n",
       " 'scaling seems heavy large benefit approach require selection basic clusters underlying tree structures since takes account effect loops contribute nontrivial correlations cavity distribution',\n",
       " 'loop correction strategy applicable class models perturbative expansion around bethe approximation makes sense e models large loops relatively weak interactions',\n",
       " 'principal requirement magnitude pair variable cumulants cavity distributions order smaller single variable cumulants third order cumulants even smaller etc',\n",
       " 'heuristics based strategy allow good algorithms performing well outside parameter regimes citation',\n",
       " 'far approach developed discrete variable models abstract citation versus practical level citation',\n",
       " 'paper apply idea graphical models continuous variables',\n",
       " 'derive loop corrected belief propagation equations simple tractable gaussian models yielding message passing scheme besides correct average marginals also yields correct variances',\n",
       " 'discuss approaches potentially applicable cases extra function approximations necessary relation expectation propagation',\n",
       " 'product loop corrected belief propagation equations algorithm calculates exact covariance matrices gaussian models like one discussed citation without explicitly using linear response',\n",
       " 'abstract',\n",
       " 'paper derive equations loop corrected belief propagation continuous variable gaussian model',\n",
       " 'using exactness averages belief propagation gaussian models different way obtaining covariances found based belief propagation cavity graphs',\n",
       " 'discuss relation loop correction algorithm expectation propagation algorithms case model longer gaussian slightly perturbed nonlinear terms',\n",
       " 'introduction',\n",
       " 'message passing techniques graphical models allow computation approximate marginal probabilities time interval scaling polynomially model size',\n",
       " 'discovery consequently revolutionized several fields applications past years error correcting codes vision probably prominent examples',\n",
       " 'many cases corresponding graphs loopy implying either error resulting application loopy belief propagation bp negligible particular model tolerated particular purpose bp serves',\n",
       " 'cases sophisticated refinements bp necessary taking account part loop errors',\n",
       " 'finding optimal treatment loop errors motivates active field research different solutions applying different model classes developed',\n",
       " 'models involving many short loops like regular lattices cvm type approaches work well citation tree ep approaches citation',\n",
       " 'latter may also applied correct incidental large loop',\n",
       " 'unifying frameworks like region graphs citation lead general strategies selecting basic clusters underlying approaches general model classes',\n",
       " 'recent analysis shown local update equations bp may interpreted zero order term expansion cavity connected correlations',\n",
       " 'quantities parameterizations cavity distributions e distribution neighbor variables central variable removed graph',\n",
       " 'bethe approximation bp recovered cavity distribution assumed factorize whereas first order correction local update equations obtained one takes account pair cumulants citation',\n",
       " 'estimation pair cumulants possible extra runs bp allowing new polynomial time algorithms reducing errors order symbol applying algorithms running time scales extra factor symbol citation',\n",
       " 'although scaling seems heavy large benefit approach require selection basic clusters underlying since takes account effect loops contribute nontrivial correlations cavity distribution',\n",
       " 'loop correction strategy applicable class models perturbative expansion around bethe approximation makes sense e models large loops relatively weak interactions',\n",
       " 'principal requirement magnitude pair variable cumulants cavity distributions order smaller single variable cumulants third order cumulants even smaller etc',\n",
       " 'however heuristics based strategy allow good algorithms performing well outside parameter regimes citation',\n",
       " 'far approach developed discrete variable models abstract citation versus practical level citation',\n",
       " 'paper apply idea graphical models continuous variables',\n",
       " 'derive loop corrected belief propagation equations simple tractable gaussian models yielding message passing scheme besides correct average marginals also yields correct variances',\n",
       " 'besides discuss approaches potentially applicable cases extra function approximations necessary relation expectation propagation',\n",
       " 'loop corrected belief propagation equations algorithm calculates exact covariance matrices gaussian models like one discussed citation without explicitly using linear response',\n",
       " 'abstract',\n",
       " 'defensive forecasting method transforming laws probability stated terms strategies sceptic forecasting algorithms',\n",
       " 'two known varieties defensive forecasting continuous sceptic moves assumed depend forecasts semi continuous manner produces deterministic forecasts randomized dependence sceptic moves forecasts arbitrary forecaster moves allowed randomized',\n",
       " 'note shows randomized variety obtained continuous variety smearing sceptic moves make continuous',\n",
       " 'new compared version 1 17 august 2007 report assumption version 1 outcome space symbol finite relaxed assumed compact',\n",
       " 'case symbol finite shown forecaster choose randomized forecasts concentrated finite set cardinality symbol',\n",
       " 'introduction',\n",
       " 'continuous variety defensive forecasting essentially introduced levin citation later rediscovered kakade foster citation takemura et al citation',\n",
       " 'randomized variety introduced case von mises version approach probability foster vohra citation developed among others sandroni et al citation papers however concerned asymptotic calibration',\n",
       " 'versions randomized variety proposed sandroni citation based standard probability vovk shafer citation based probability',\n",
       " 'kakade foster citation noticed calibration results require little randomization important aspect theorem',\n",
       " 'note states two simple results defensive forecasting theorem continuous variety theorem randomized variety',\n",
       " 'proof theorem obtained proof theorem blurring sceptic moves',\n",
       " 'informal discussions assuming set symbol possible outcomes finite although try make mathematical statements general possible',\n",
       " 'reader interested main ideas might choose specialize theorems proofs case finite symbol',\n",
       " 'abstract',\n",
       " 'generalization bounds learning theory based measure complexity hypothesis class used independently algorithm',\n",
       " 'contrast notion algorithmic stability used derive tight generalization bounds tailored specific learning algorithms exploiting particular properties',\n",
       " 'much learning theory existing stability analyses bounds apply scenario samples independently identically distributed',\n",
       " 'many machine learning applications however assumption hold',\n",
       " 'observations received learning algorithm often inherent temporal dependence',\n",
       " 'paper studies scenario observations drawn stationary mixing mixing sequence widely adopted assumption study non independent identically distributed processes implies dependence observations weakening time',\n",
       " 'prove novel distinct stability based generalization bounds stationary mixing mixing sequences',\n",
       " 'bounds strictly generalize bounds given independent identically distributed case apply stable learning algorithms thereby extending use stability bounds non independent identically distributed scenarios',\n",
       " 'also illustrate application mixing generalization bounds general classes learning algorithms including support vector regression kernel ridge regression support vector machines many kernel regularization based relative entropy based regularization algorithms',\n",
       " 'novel bounds thus viewed first theoretical basis use algorithms non independent identically distributed scenarios',\n",
       " 'introduction',\n",
       " 'generalization bounds learning theory based measure complexity hypothesis class used vc dimension covering numbers rademacher complexity',\n",
       " 'measures characterize class hypotheses independently algorithm',\n",
       " 'contrast notion algorithmic stability used derive bounds tailored specific learning algorithms exploit particular properties',\n",
       " 'learning algorithm stable hypothesis outputs varies limited way response small changes made training set',\n",
       " 'stability used effectively past derive tight generalization bounds citation',\n",
       " 'much learning theory existing stability analyses bounds apply scenario samples independently identically distributed independent identically distributed',\n",
       " 'many machine learning applications assumption however hold fact independent identically distributed assumption tested derived data analysis',\n",
       " 'observations received learning algorithm often inherent temporal dependence',\n",
       " 'clear system diagnosis time series prediction problems',\n",
       " 'prices different stocks day stock different days may dependent',\n",
       " 'less apparent time dependency may affect data sampled many tasks well',\n",
       " 'paper studies scenario observations drawn stationary mixing mixing sequence widely adopted assumption study non independent identically distributed processes implies dependence observations weakening time citation',\n",
       " 'prove novel distinct stability based generalization bounds stationary mixing mixing sequences',\n",
       " 'bounds strictly generalize bounds given independent identically distributed case apply stable learning algorithms thereby extending usefulness stability bounds non independent identically distributed scenarios',\n",
       " 'proofs based independent block technique described citation attributed citation commonly used contexts',\n",
       " 'analysis differs previous uses technique blocks points considered equal size',\n",
       " 'analysis stationary mixing sequences make use generalized version mcdiarmid inequality citation holds mixing sequences',\n",
       " 'leads stability based generalization bounds standard exponential form',\n",
       " 'generalization bounds stationary mixing sequences cover general non independent identically distributed scenario use standard mcdiarmid inequality however unlike mixing case mixing bound presented purely exponential bound contains additive term depending mixing coefficient',\n",
       " 'also illustrate application mixing generalization bounds general classes learning algorithms including support vector regression svr citation kernel ridge regression citation support vector machines svms citation',\n",
       " 'support vector regression svr citation used context time series prediction independent identically distributed assumption hold good experimental results citation',\n",
       " 'knowledge use algorithms non independent identically distributed scenarios previously supported theoretical analysis',\n",
       " 'stability bounds give svr svms many kernel regularization based relative entropy based regularization algorithms thus viewed first theoretical basis use scenarios',\n",
       " 'following sections organized follows',\n",
       " 'section introduce necessary definitions non independent identically distributed problems considering discuss learning scenarios context',\n",
       " 'gives main generalization bounds stationary mixing sequences based stability well illustration applications general kernel regularization based algorithms including svr krr svms well relative entropy based regularization algorithms',\n",
       " 'section presents first known stability bounds general stationary mixing scenario',\n",
       " 'abstract',\n",
       " 'generalization bounds learning theory based measure complexity hypothesis class used independently algorithm',\n",
       " 'contrast notion algorithmic stability used derive tight generalization bounds tailored specific learning algorithms exploiting particular properties',\n",
       " 'however much learning theory existing stability analyses bounds apply scenario samples independently identically distributed',\n",
       " 'many machine learning applications however assumption hold',\n",
       " 'observations received learning algorithm often inherent temporal dependence',\n",
       " 'paper studies scenario observations drawn stationary symbol symbol sequence widely adopted assumption study processes implies dependence observations weakening time',\n",
       " 'prove novel distinct generalization bounds stationary symbol symbol sequences',\n",
       " 'bounds strictly generalize bounds given iid case apply stable learning algorithms thereby extending use scenarios',\n",
       " 'also illustrate application symbol generalization bounds general classes learning algorithms including support vector regression kernel ridge regression support vector machines many kernel relative regularization algorithms',\n",
       " 'novel bounds thus viewed first theoretical basis use algorithms scenarios',\n",
       " 'introduction',\n",
       " 'generalization bounds learning theory based measure complexity hypothesis class used covering numbers rademacher complexity',\n",
       " 'measures characterize class hypotheses independently algorithm',\n",
       " 'contrast notion algorithmic stability used derive bounds tailored specific learning algorithms exploit particular properties',\n",
       " 'learning algorithm stable hypothesis outputs varies limited way response small changes made training set',\n",
       " 'algorithmic stability used effectively past derive tight generalization bounds citation',\n",
       " 'much learning theory existing stability analyses bounds apply scenario samples independently identically distributed iid',\n",
       " 'many machine learning applications assumption however hold fact iid assumption tested derived data analysis',\n",
       " 'observations received learning algorithm often inherent temporal dependence',\n",
       " 'clear system diagnosis time series prediction problems',\n",
       " 'clearly prices different stocks day stock different days may dependent',\n",
       " 'less apparent time dependency may affect data sampled many tasks well',\n",
       " 'paper studies scenario observations drawn stationary symbol symbol sequence widely adopted assumption study processes implies dependence observations weakening time citation',\n",
       " 'prove novel distinct generalization bounds stationary symbol symbol sequences',\n",
       " 'bounds strictly generalize bounds given iid case apply stable learning algorithms thereby extending usefulness scenarios',\n",
       " 'proofs based independent block technique described citation attributed citation commonly used contexts',\n",
       " 'however analysis differs previous uses technique blocks points considered equal size',\n",
       " 'analysis stationary symbol sequences make use generalized version mcdiarmid inequality citation holds symbol sequences',\n",
       " 'leads generalization bounds standard exponential form',\n",
       " 'generalization bounds stationary symbol sequences cover general scenario use standard mcdiarmid inequality however unlike symbol case symbol bound presented purely exponential bound contains additive term depending mixing coefficient',\n",
       " 'also illustrate application symbol generalization bounds general classes learning algorithms including support vector regression svr citation kernel ridge regression citation support vector machines svms citation',\n",
       " 'algorithms support vector regression svr citation used context time series prediction iid assumption hold good experimental results citation',\n",
       " 'knowledge use algorithms scenarios previously supported theoretical analysis',\n",
       " 'stability bounds give svr svms many kernel relative regularization algorithms thus viewed first theoretical basis use scenarios',\n",
       " 'following sections organized follows',\n",
       " 'introduce necessary definitions problems considering discuss learning scenarios context',\n",
       " 'gives main generalization bounds stationary symbol sequences based stability well illustration applications general kernel algorithms including svr krr svms well relative regularization algorithms',\n",
       " 'finally presents first known stability bounds general stationary symbol scenario',\n",
       " 'abstract',\n",
       " 'generalization bounds learning theory based measure complexity hypothesis class used independently algorithm',\n",
       " 'contrast notion algorithmic stability used derive tight generalization bounds tailored specific learning algorithms exploiting particular properties',\n",
       " 'however much learning theory existing stability analyses bounds apply scenario samples independently identically distributed',\n",
       " 'many machine learning applications however assumption hold',\n",
       " 'observations received learning algorithm often inherent temporal dependence',\n",
       " 'paper studies scenario observations drawn stationary symbol symbol sequence widely adopted assumption study processes implies dependence observations weakening time',\n",
       " 'prove novel distinct generalization bounds stationary symbol symbol sequences',\n",
       " 'bounds strictly generalize bounds given iid case apply stable learning algorithms thereby extending use scenarios',\n",
       " 'also illustrate application symbol generalization bounds general classes learning algorithms including support vector regression kernel ridge regression support vector machines many kernel relative regularization algorithms',\n",
       " 'novel bounds thus viewed first theoretical basis use algorithms scenarios',\n",
       " 'introduction',\n",
       " 'generalization bounds learning theory based measure complexity hypothesis class used covering numbers rademacher complexity',\n",
       " 'measures characterize class hypotheses independently algorithm',\n",
       " 'contrast notion algorithmic stability used derive bounds tailored specific learning algorithms exploit particular properties',\n",
       " 'learning algorithm stable hypothesis outputs varies limited way response small changes made training set',\n",
       " 'algorithmic stability used effectively past derive tight generalization bounds citation',\n",
       " 'much learning theory existing stability analyses bounds apply scenario samples independently identically distributed iid',\n",
       " 'many machine learning applications assumption however hold fact iid assumption tested derived data analysis',\n",
       " 'observations received learning algorithm often inherent temporal dependence',\n",
       " 'clear system diagnosis time series prediction problems',\n",
       " 'clearly prices different stocks day stock different days may dependent',\n",
       " 'less apparent time dependency may affect data sampled many tasks well',\n",
       " 'paper studies scenario observations drawn stationary symbol symbol sequence widely adopted assumption study processes implies dependence observations weakening time citation',\n",
       " 'prove novel distinct generalization bounds stationary symbol symbol sequences',\n",
       " 'bounds strictly generalize bounds given iid case apply stable learning algorithms thereby extending usefulness scenarios',\n",
       " 'proofs based independent block technique described citation attributed citation commonly used contextsmisc',\n",
       " 'however analysis differs previous uses technique blocks points considered equal size',\n",
       " 'analysis stationary symbol sequences make use generalized version mcdiarmid inequality citation holds symbol sequences',\n",
       " 'leads generalization bounds standard exponential form',\n",
       " 'generalization bounds stationary symbol sequences cover general scenario use standard mcdiarmid inequality however unlike symbol case symbol bound presented purely exponential bound contains additive term depending mixing coefficient',\n",
       " 'also illustrate application symbol generalization bounds general classes learning algorithms including support vector regression svr citation kernel ridge regression citation support vector machines svms citation',\n",
       " 'algorithms support vector regression svr citation used context time series prediction iid assumption hold good experimental results citation',\n",
       " 'knowledge use algorithms scenarios previously supported theoretical analysis',\n",
       " 'stability bounds give svr svms many kernel relative regularization algorithms thus viewed first theoretical basis use scenarios',\n",
       " 'following sections organized follows',\n",
       " 'introduce necessary definitions problems considering discuss learning scenarios context',\n",
       " 'gives main generalization bounds stationary symbol sequences based stability well illustration applications general kernel algorithms including svr krr svms well relative regularization algorithms',\n",
       " 'finally presents first known stability bounds general stationary symbol scenario',\n",
       " 'abstract',\n",
       " 'paper studies quantum annealing qa clustering seen extension simulated annealing sa',\n",
       " 'derive qa algorithm clustering propose annealing schedule crucial practice',\n",
       " 'show proposed qa algorithm finds better clustering assignments sa',\n",
       " 'qa easy sa implement',\n",
       " 'introduction',\n",
       " 'one popular methods data mining',\n",
       " 'clustering problems formulated optimization problems solved algorithms example em algorithm convex relaxation',\n",
       " 'clustering typically np hard',\n",
       " 'simulated annealing sa citation promising candidate',\n",
       " 'proved sa able find global optimum slow cooling schedule temperature',\n",
       " 'schedule practice slow clustering large amount data well known sa still finds reasonably good solution even faster schedule citeauthor geman number proposed',\n",
       " 'statistical mechanics quantum annealing qa proposed novel alternative sa citation',\n",
       " 'adds another dimension sa annealing see fig',\n",
       " 'seen extension sa',\n",
       " 'succeeded specific problems e g ising model statistical mechanics still unclear qa works better sa general',\n",
       " 'actually think qa intuitively helps clustering apply qa clustering procedure derive algorithm',\n",
       " 'derived qa algorithm depends definition quantum effect',\n",
       " 'propose quantum effect leads search strategy fit clustering',\n",
       " 'contribution 1 propose qa based optimization algorithm clustering particular quantum effect clustering good annealing schedule crucial applications 2 experimentally show proposed algorithm optimizes clustering assignments better sa',\n",
       " 'also show proposed algorithm easy sa implement',\n",
       " 'algorithm propose markov chain monte carlo mcmc sampler call qa st sampler',\n",
       " 'explain later naive qa sampler intractable even mcmc',\n",
       " 'approximate qa suzuki trotter st expansion citation derive tractable sampler qa st sampler',\n",
       " 'st looks like parallel sas interaction see fig',\n",
       " 'beginning annealing process qa st almost sas',\n",
       " 'qa st finds local optima independently',\n",
       " 'annealing process continues interaction fig becomes stronger move states closer',\n",
       " 'st end picks state lowest energy states final solution',\n",
       " 'st proposed quantum effect works well clustering',\n",
       " 'example data points grouped four clusters',\n",
       " 'symbol locally optimal globally optimal',\n",
       " 'symbol equal two symbol symbol fig correspond symbol symbol fig',\n",
       " 'local optima interaction fig allows search better clustering assignment',\n",
       " 'effect defines distance metric clustering assignments',\n",
       " 'case proposed locates',\n",
       " 'interaction gives good chance go makes closer see fig',\n",
       " 'proposed algorithm actually finds',\n",
       " 'example',\n",
       " 'similar situation often occurs clustering',\n",
       " 'algorithms cases give almost globally optimal solutions like majority data points well clustered',\n",
       " 'better clustering assignment constructed picking well clustered data points many sub optimal clustering assignments',\n",
       " 'assignment constructed way located sub optimal ones proposed quantum effect qa st find better assignment sub optimal ones']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e133cccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###: abstract\n",
      "OWNX: transporter analyses conducted 141 organisms whose complete genome sequences available\n",
      "OWNX\twe: organism complete set membrane transport systems identified predicted functions classified protein families based transporter classification system\n",
      "OWNX\twe: organisms larger genome sizes generally possessed relatively greater number transport systems\n",
      "MISC: prokaryotes unicellular eukaryotes significant factor increase transporter content genome size greater diversity transporter types\n",
      "OWNX\twe: contrast multicellular eukaryotes greater number paralogs specific transporter families important factor increase transporter content genome size\n",
      "MISC: eukaryotic prokaryotic intracellular pathogens endosymbionts exhibited markedly limited transport capabilities\n",
      "OWNX\twe: hierarchical clustering phylogenetic profiles transporter families derived presence absence certain transporter family showed clustering patterns organisms correlated evolutionary history overall physiology lifestyles\n",
      "###: introduction\n",
      "MISC: membrane transport systems play essential roles cellular metabolism activities\n",
      "MISC: transporters function acquisition organic nutrients maintenance ion homeostasis extrusion toxic waste compounds environmental sensing cell communication important cellular functions citation\n",
      "MISC: various transport systems differ putative membrane topology energy coupling mechanisms substrate specificities citation\n",
      "###: among prevailing energy sources adenosine triphosphate phosphoenolpyruvate chemiosmotic energy form sodium ion proton electrochemical gradients\n",
      "OWNX: transporter classification system represents systematic approach classify transport systems according mode transport energy coupling mechanism molecular phylogeny substrate specificity citation citation\n",
      "OWNX: transport mode energy coupling mechanism serve primary basis classification relatively stable characteristics\n",
      "OWNX: four major classes solute transporters transporter classification system channels primary transporters secondary transporters group translocators\n",
      "MISC: transporters unknown mechanism function included distinct class\n",
      "MISC: channels transporters transport water specific types ions hydrophilic small molecules concentration electrical gradient higher rates transport lower stereospecificity transporter classes\n",
      "###: primary active transporters couple transport process primary source energy\n",
      "MISC: secondary transporters utilize ion solute electrochemical gradient motive force drive transport process\n",
      "MISC: coli lacy lactose permease citation citation probably one best characterized secondary transporters citation\n",
      "MISC: group translocators modify substrates transport process\n",
      "MISC: example coli mtla mannitol pts transporter phosphorylates exogenous mannitol using phosphoenolpyruvate phosphoryl donor energy source releases phosphate ester cell cytoplasm citation citation\n",
      "MISC: transporter class classified individual families subfamilies according function phylogeny substrate specificity citation\n",
      "MISC: since advent genomic sequencing technologies complete sequences 200 prokaryotic eukaryotic genomes published date representing wide range species archaea human\n",
      "OWNX: also additional genome sequencing projects currently underway around world citation citation\n",
      "MISC: convenient effective computational methods required handle analyze immense amount data generated sequencing projects\n",
      "OWNX: look transport proteins vital understanding metabolic capability sequenced organisms\n",
      "MISC: however often problematic annotate transport proteins current primary annotation methods occurrence large complex transporter gene families cassette superfamily citation citation major facilitator superfamily citation citation presence multiple transporter gene paralogs many organisms\n",
      "MISC: working systematic analysis cellular membrane transport systems\n",
      "MISC: previously reported comprehensive analysis transport systems 18 prokaryotic organisms citation citation yeast citation\n",
      "MISC: expand analyses 141 species compare fundamental differences membrane transport systems prokaryotes eukaryotes\n",
      "MISC: phylogenetic profiling transporter families predicted substrates utilized investigate relevance transport capabilities overall physiology prokaryotes eukaryotes\n",
      "###: abstract\n",
      "###: central problem bioinformatics gene regulation find binding sites regulatory proteins\n",
      "AIMX: one promising approaches toward identifying short fuzzy sequence patterns comparative analysis orthologous intergenic regions related species\n",
      "MISC: analysis complicated various factors\n",
      "MISC: first one needs take phylogenetic relationship species account order distinguish conservation due occurrence functional sites spurious conservation due evolutionary proximity\n",
      "MISC: second one deal complexities multiple alignments orthologous intergenic regions one consider possibility functional sites may occur outside conserved segments\n",
      "AIMX: present new motif sampling algorithm phylogibbs runs arbitrary collections multiple local sequence alignments orthologous sequences\n",
      "OWNX\twe: algorithm searches ways arbitrary number binding sites arbitrary number transcription factors assigned multiple sequence alignments\n",
      "AIMX: binding site configurations scored bayesian probabilistic model treats aligned sequences model evolution binding sites background intergenic dna\n",
      "MISC: model takes phylogenetic relationship species alignment explicitly account\n",
      "OWNX: algorithm uses simulated annealing monte carlo sampling rigorously assign posterior probabilities binding sites reports\n",
      "OWNX: tests synthetic data real data five saccharomyces species algorithm performs significantly better four algorithms including algorithms also take phylogeny account\n",
      "OWNX: results also show contrast algorithms phylogibbs make realistic estimates reliability predictions\n",
      "OWNX\twe: tests suggest running multiple alignment single gene upstream region phylogibbs average recovers 50 percent binding sites cerevisiae specificity 50 percent 33 percent binding sites specificity 85 percent\n",
      "OWNX\twe: also tested phylogibbs collections multiple alignments intergenic regions recently annotated based data contain binding sites tf\n",
      "OWNX: compared phylogibbs results previous analysis data using six algorithms\n",
      "MISC: 16 21 tfs methods failed find significant motif phylogibbs recover motif matches literature consensus\n",
      "MISC: 11 cases disagreement results compiled lists known target genes literature found running phylogibbs regulatory regions yielded binding motif matching literature consensus one cases\n",
      "MISC: interestingly literature gene lists little overlap targets annotated based data\n",
      "MISC: phylogibbs code downloaded link link\n",
      "OWNX: full set predicted sites tests yeast available link\n",
      "###: introduction\n",
      "MISC: transcription factors proteins bind manner short dna segments commonly intergenic dna upstream gene activate suppress gene transcription\n",
      "OWNX: domains recognize collections short related dna sequences\n",
      "MISC: one generally finds although unique combination bases shared binding sites although different bases occur position clear biases distribution bases occur position binding sites\n",
      "MISC: common mathematical representation motif takes variability account weight matrix citation citation w whose components w give probabilities finding base c g position binding site\n",
      "MISC: main assumption underlying mathematical representation bases occurring different positions binding site probabilistically independent\n",
      "MISC: turn follows conditions citation assumption binding energy protein dna sum pairwise contact energies individual nucleotides protein\n",
      "OWNX: several algorithms based wm representation detect ab initio binding sites common tf collection dna sequences citation citation\n",
      "OWNX: algorithms broadly fall two classes\n",
      "OWNX: one class meme citation typical representative searches space wms wm best explain observed sequences\n",
      "MISC: class gibbs sampling algorithms gibbs motif sampler citation citation typical representative instead samples space multiple alignments small sequence segments search one likely consist samples common wm\n",
      "OWNX\twe: crucial factor success ab initio methods ratio number binding sites total amount dna collection sequences\n",
      "OWNX\twe: larger number binding sites set smaller total amount dna likely ab initio methods discover binding sites among dna sequences\n",
      "MISC\tthe: order ensure reasonable chance success one thus needs provide methods collections sequences highly enriched binding sites common tf\n",
      "OWNX: one possibility use sets upstream regions genes appear microarray experiments bound common tf experiments\n",
      "OWNX: another possibility use upstream regions orthologous genes related organisms\n",
      "OWNX: assumption regulation ancestor gene thus binding sites conserved orthologs descend\n",
      "OWNX\twe: latter approach general complicated number factors\n",
      "OWNX: searching regulatory sites sequences phylogenetically related upstream regions different genes organism one may simply look short sequence motifs overrepresented among input sequences\n",
      "OWNX: set species orthologous sequences derive sufficiently diverged one may simply choose ignore phylogenetic relationship sequences treat orthologous sequences way sequences phylogenetically related\n",
      "MISC: instance approach taken mccue et al citation citation gibbs motif sampler algorithm citation citation used upstream regions bacteria\n",
      "MISC: however approach applicable datasets containing closely related species sequences exhibit significant amounts similarity simply evolutionary proximity\n",
      "AIMX: moreover amount similarity depend phylogenetic distance species clear finding conserved sequence motifs orthologous sequences closely related species much less indicative function finding sequence motifs conserved distant species\n",
      "OWNX: one general thus distinguish conservation due functional constraints conservation due evolutionary proximity correctly phylogenetic relationship sequences taken account\n",
      "OWNX: second challenge using orthologous intergenic sequences multiple species nontrivial structure multiple alignments\n",
      "BASE: one typically finds heterogeneous pattern conservation blocks different sizes covering different subsets species interspersed sequence segments show little similarity sequences species\n",
      "AIMX: technique phylogenetic footprinting restricts attention sequence segments genome interest show significant conservation species\n",
      "MISC: conserved regions multiple genes searched common motifs variety techniques\n",
      "MISC: unclear however extent regulatory sites restricted conserved segments\n",
      "MISC: instance several studies drosophila yeast citation citation shown strong correlation experimentally annotated binding sites occur whether region conserved\n",
      "OWNX: thus least yeast flies considerable information lost focusing conserved regions\n",
      "OWNX: thus decided retain entire patchwork pattern conserved sequence blocks unaligned segments\n",
      "MISC: strategy implemented gibbs sampling approach preliminary account algorithm presented citation\n",
      "OWNX: algorithm operates arbitrary collections phylogenetically related sequences orthologous intergenic regions sequences phylogenetically related upstream regions different genes organism\n",
      "AIMX: phylogenetically related groups sequences input local multiple alignments clearly similar sequence segments aligned blocks sequence segments marginal similarity left unaligned citation\n",
      "MISC: although algorithm also take global multiple alignments input believe often force phylogenetically unrelated segments aligned blocks\n",
      "MISC: may adversely affect performance algorithm\n",
      "MISC: score putative sites within blocks aligned sequences evolutionary model takes phylogenetic relationships species account putative sites unaligned segments treated independent occurrences\n",
      "###: bayesian model defines probability distribution arbitrary placements putative binding sites multiple motifs sample monte carlo markov chain\n",
      "OWNX: first use simulated annealing search globally optimal configuration binding sites\n",
      "MISC: motifs configuration tracked sampling run estimate realistic posterior probabilities binding sites algorithm reports\n",
      "OWNX: recently number algorithms developed search regulatory motifs groups phylogenetically related sequences\n",
      "OWNX: probably first algorithm proposed generalization consensus algorithm citation called phylocon citation\n",
      "MISC: phylocon operates sets genes orthologs\n",
      "OWNX: greedy algorithm first finds ungapped alignments similar sequence segments sets orthologous sequences combines alignments different upstream regions larger alignments\n",
      "OWNX: algorithm take phylogenetic information account closely related sequences treated distantly related sequences\n",
      "MISC: drawbacks algorithm assumes motif exactly one site intergenic regions assumes site conserved orthologs\n",
      "OWNX: closely related phylogibbs approach two recent algorithms citation citation generalize meme citation take phylogenetic relationships species account\n",
      "OWNX: main difference emnem phyme phyme uses evolutionary model evolution binding sites phylogibbs takes account binding sites evolve constraints set wm whereas emnem simply assumes overall slower rate evolution binding sites background sequences\n",
      "OWNX: another difference phyme like phylogibbs treats multiple alignment flexibly emnem demands global multiple alignment\n",
      "MISC: main difference phylogibbs algorithms course phylogibbs takes motif sampling approach allows us search multiple motifs parallel whereas phyme emnem use expectation maximization search one wm time\n",
      "OWNX: following sections first describe bayesian model assigns posterior probability configuration binding sites multiple motifs assigned input sequences\n",
      "OWNX: start describing model phylogenetically unrelated sequences essentially equivalent model used gibbs motif sampler citation citation describe model extended datasets contain phylogenetically related sequences\n",
      "BASE: describe move set search state space possible configurations annealing tracking strategy use identify significant groups sites\n",
      "OWNX: present examples performance algorithms synthetic real data\n",
      "OWNX: synthetic datasets consist mixtures wm samples random sequences accordance assumptions algorithms make\n",
      "OWNX: allows us compare performance algorithms idealized situation contain complexities real data\n",
      "OWNX\twe: tests also show extent binding sites recovered idealized data function quality wms number sites available number species available phylogenetic distances\n",
      "OWNX: tests real data use 200 upstream regions saccharomyces cerevisiae known binding sites collection citation compare ability different algorithms recover sites running multiple alignments orthologs upstream regions recently sequenced saccharomyces genomes citation citation\n",
      "OWNX: finally run phylogibbs collections upstream region alignments annotated citation contain binding sites common tf based data experiments extensively compare phylogibbs results annotations citation literature\n"
     ]
    }
   ],
   "source": [
    "# Use the trained classifier to predict labels for unlabeled data\n",
    "unlabeled_data = []\n",
    "\n",
    "for file in os.listdir(unlabeled_dataset_path):\n",
    "    if os.path.isfile(os.path.join(unlabeled_dataset_path, file)):\n",
    "        with open(os.path.join(unlabeled_dataset_path, file), 'r', encoding='utf-8') as f:\n",
    "            unlabeled_data.extend(remove_stop_punc(line.strip()) for line in f.readlines())\n",
    "\n",
    "# Vectorize the unlabeled data\n",
    "unlabeled_data_vectorized = vectorizer.transform(unlabeled_data)\n",
    "\n",
    "# Predict labels for the unlabeled data\n",
    "predicted_labels = classifier.predict(unlabeled_data_vectorized)\n",
    "\n",
    "# Print or save the predicted labels for further use\n",
    "for sentence, label in zip(unlabeled_data, predicted_labels):\n",
    "    print(f\"{label}: {sentence}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef59d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cc3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e50b9e20",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue;\">Task 2: Use TF-IDF to vectorize the sentences.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005a52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ada07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0a7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19599ee4",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue;\">Task 3: Use Scikit learn to create a (nave bayes) classifier.</span>\n",
    "\n",
    "<span style=\"color:blue;\">**First create a classifier (nave bayes) to classify the given dataset into 6 categories: (AIMX, OWNX, CONT, BASE, NUMBER, and MISC).<br>Then, use the classifier to label the sentences in the unlabeled dataset.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b03e17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7891a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383fa01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d52ebb92",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue;\">Task 4: Summarize your work and your findings in a few sentences.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2fc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f139d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e8ecbb8",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue;\">BONUS [Extra 5% added to any workshops]: Use other classification approaches to label the unlabeled sentences. Evaluate your work using precision, recall, and f1 score.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e055a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2187d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdfeaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
